class GPTConfig:
    block_size = 1024  # context size
    vocab_size = 50257  # vocabulary size
    n_layer = 24  # number of transformer blocks
    n_head = 16  # number of attention heads
    n_embd = 1024  # embedding dimension